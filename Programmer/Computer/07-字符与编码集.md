<!-- TOC -->

- [历史](#历史)
    - [ASCII](#ascii)
    - [Extended ASCII](#extended-ascii)
    - [国际化](#国际化)
- [Unicode](#unicode)
    - [UTF-8](#utf-8)
    - [UTF-16](#utf-16)
- [中文编码集](#中文编码集)
- [资源](#资源)

<!-- /TOC -->

# 历史

## ASCII

- 使用 7 个 bits 就可以完全表示 ASCII 码
- 包含 95 个可打印字符
- 33 个不可打印字符(包括控制字符)

## Extended ASCII

- 常见数学运算符
- 带音标的欧洲字符
- 表格符等

## 国际化

- 欧洲、中亚、东亚、拉丁美洲国家的语言多样性
- 语言体系不一样, 不以有限字符组合的语言

# Unicode

- 兼容全球的字符集
- 统一码、万国码、单一码
- Unicode 定义了世界通用的符号集, UTF-* 实现了编码
- UTF-8 以字节为单位对 Unicode 进行编码

> UTF-8 字符编码格式与 UTF-16 字符编码格式都是当今非常常用的字符编码格式，它们都是根据 Unicode 这一计算机工业编码标准进行制定的。当今现代化计算机操作系统几乎都使用 UTF-8 作为其默认的系统字符编码格式，大部分集成开发环境也几乎默认使用 UTF-8 编码格式。Google 在 2008 年的报告中指出，在互联网上，UTF-8 编码已经成为 HTML 文件使用最多的字符编码格式。<br>
> 在当今许多文本解析上，大多都以 UTF-16 编码来收集源文件以及文本上的字符，因为 UTF-16 编码格式的可变性小，而且大部分情况下 2 个字节即可表示一个常用字符，因此用 UTF-16 编码格式的字符串一来不怎么耗费内存，二来能方便地确定字符串的长度，从而可以方便地进行插入、修改、删除等操作。因此对于字符串的编辑而言，它比 UTF-8 更具优势。<br>

## UTF-8

> UTF-8 字符编码是一种变长的字符编码格式，可兼容之前已有的 ASCII 编码格式。它在 1993 年 1 月首次官方发布，当时 UTF-8 编码的字符长度最多可长达 6 个字节，也就是说当时一个 UTF-8 编码的字符可占用 1 到 6 个字节，比如如果一个字符是与 ASCII 码相兼容的，那么它就只占 1 个字节。到了 2003 年 11 月，UTF-8 做了一些改动然后再次发布，这是为了让 UTF-8 与 UTF-16 能完整兼容转换，对 UTF-8 的表达范围做了裁剪，将它的最大长度缩减到了 4 个字节，并且要求它必须满足 [RFC 3629](https://datatracker.ietf.org/doc/rfc3629/) 标准中的约束。现在我们用的 UTF-8 编码格式都是基于 2003 年发布的标准实现的。

> 我们上面探讨了 UTF-8 是一种变长编码格式，其长度在 1 个字节到 4 个字节之间，那么一个 UTF-8 编码的字符是如何表达的呢？一个 UTF-8 编码的字符由两部分构成，第一部分是用于标识该字符一共需要多少字节的前缀比特标志。这个前缀比特要看第一个字节的高 5 位，如果是 0，表示当前字符由 1 个字节构成；如果是 3，表示当前字符由 2 个字节构成；如果是 7 表示当前字符由 3 个字节构成；如果是 15，则表示当前字符由 4 个字节构成。其实这也就意味着通过观察第一个字节的前导 1 的个数即可判断出当前字符由多少个字节构成。第二部分则是该字符的码点（codepoint）。所谓码点就是用于表示一个特定字符具有实际意义的编码值，该编码值是由 Unicode 组织制定的。比如对于一个兼容 ASCII 码的 UTF-8 编码字符 A 来说，其完整的二进制编码为 01000001。可见其前导 1 的个数为 0，说明它就由 1 个字节构成。然后它的码点即为 100 0001，即十六进制的 0x41。

字节个数|码点比特个数|起始码点|最后码点|字节 1|字节 2|字节 3|字节 4
:---:|:---:|:---|:---|:---|:---|:---|:---
1|7|0x0000|0x007F|0xxxxxxx|N/A|N/A|N/A
2|11|0x0080|0x07FF|110xxxxx|10xxxxxx|N/A|N/A
3|16|0x0800|0xFFFF|1110xxxx|10xxxxxx|10xxxxxx|N/A
4|21|0x10000|0x10FFFF|11110xxx|10xxxxxx|10xxxxxx|10xxxxxx

上表中 x 符号表示码点的一个比特。我们看到，为了与 ASCII 码完全兼容，Unicdoe 在制定 UTF-8 编码时，将没有任何前导 1 的字节表示为单字节 UTF-8 编码，然后从由 2 个字节构成的 UTF-8 编码开始，有多少个前导 1 就表明当前字符占用多少个字节。然后，对于一个字符的 UTF-8 编码，后续字节的编码都以 10 开头，这么做的好处是可用于校验当前字符编码的正确性，也可以避免解析到用于表示 UTF-8 字符串的结束符 `\0` 字符，因为它的编码值为 0，而有了前导 10 比特，则当前字节的最小值为 0x80，所以不可能会出现 0 的情况。这种特性也称为自同步（self-synchronizing）特性，它可在遍历 UTF-8 编码字符串的时候方便校验当前字符编码的正确性。

我们下面举一个具体例子来说明一个字符的 UTF-8 编码是如何构成的，我们这里用欧元符号 `€` 进行举例说明。在 Unicode 标准中，欧元符号 `€` 的码点为 `0x20AC`。那么可以根据以下步骤来构造出其 UTF-8 编码。

1. 由于 0x20AC 这个码点坐落于 0x0800 到 0xFFFF 之间，因此它最终的 UTF-8 编码应该由 3 个字节构成。
2. 我们将 0x20AC 用二进制数来表示，为 0010 0000 1010 1100。随后我们将这些比特插入到相应字节中。
3. 字节 1 具有 4 位固定前导比特 1110，而低 4 位用于存放码点的比特，因此字节 1 正好可以将码点的高 4 位放进去，那么得到 1110 0010。
4. 字节 2 具有 2 个固定的前导比特 10，可存放 6 位码点比特，因此把后续 6 位码点的二进制比特插入进去得到 1000 0010。
5. 字节 3 具有两个固定的前导比特 10，可存放 6 位码点比特，因此我们可以将剩余的 6 位码点二进制比特插入进去得到 1010 1100。

这样，我们整理得到欧元符号 `€` 的 UTF-8 编码的二进制表示为：1110 0010 1000 0010 10101100。用十六进制表达则是 0xE282AC。

## UTF-16

> 在 20 世纪 80 年代，人们开发出了双字节字符编码格式，那时就将它称为“Unicode”。随后，随着各种语言符号的加入，人们很快发现单单用双字节来表示一个字符远远不够，而此时已经有许多开发商基于这种双字节字符编码做了许多大型项目。比如 Java 一开始就是基于这种双字节编码的字符格式的，所以它能够支持使用汉字或其他文字来定义某个标识符，而不仅仅用 ASCII 码字符。到了 1996 年，Unicode 标准开发了 2.0 版本，将原先的双字节字符编码改造为变长的字符编码格式，称为 UTF-16 字符编码，而之前的“Unicode”则改称为“UCS-2”编码格式，其中 UCS 表示通用字符集。

> 因此，UTF-16 也是变长的 Unicode 字符编码格式，不过它与 UTF-8 不同的是，它只有两种长度，一种是占用 2 字节的编码格式，这种编码格式与 UCS-2 完全兼容；还有一种就是 4 字节编码格式。UTF-16 也有“码点”这个概念，并且一个字符的码点与 UTF-8 编码中的码点值都是一样的，因为这些都是由 Unicode 组织来制定的。

> UTF-16 编码根据字符对应的码点值，由三种不同区间范围而做出了不同的定义。

1. 从 0x0000 到 0x7FFF 以及从 0xE000 到 0xFFFF 两个区间范围

> 坐落在这两个区间范围内的 UTF-16 编码表示起来非常简单，就是当前字符所对应的码点值本身。这也是 UTF-16 与 UCS-2 相兼容的区间。Unicode 将坐落于这两个区间范围内的码点称为基本多语言平面（Basic Multilingual Plane），简称 BMP。比如，像美元 `$` 符号，它在 Unicode 中的码点与 ASCII 码中的一样，均为 0x24，所以它的 UTF-16 编码即为 0x0024。注意，尽管它用一个字节即可表示，但对于 UTF-16 来说，仍然需要占用 2 个字节。而欧元符号在 Unicode 中的码点为 0x20AC，所以它对应的 Unicode 编码值即为 0x20AC。

2. 从 0x010000 到 0x10FFFF 范围

> 我们看到，这个区间内的码点用两个字节已经无法表达，所以对于 UTF-16 编码而言就需要动用 4 个字节进行描述。这个范围区间又称为补充平面（Supplementary Plane），像 Emoji、一些历史脚本、非常少用的汉字等都坐落于此平面中。那么在此范围内的 UTF-16 编码应该如何计算呢？可以通过以下三步来获得：
> 1. 将码点值减去 0x010000，然后取差的低 20 位，使得结果留在 0x000000 到 0x0FFFFF。
> 2. 取步骤 1 所得结果的高 10 位，范围在 0x0000 到 0x03FF，将它加上 0xD800，得到第一个 16 位编码单元，这也称为高位替换，该值的范围在 0xD800 到 0xDBFF。
> 3. 对于由步骤 1 所得结果的低 10 位（范围也在 0x0000 到 0x03FF），将它加上 0xDC00，得到第二个 16 位编码单元，这也称为低位替换，该值的范围在 0xDC00 到 0xDFFF。

> 我们这里举两个例子来说明码点落在 0x010000 到 0x10FFFF 范围字符的 UTF-16 编码如何表示。首先我们看一个德撒律字母，该字母的码点定义为 0x10437。第一步，我们先将该码点值减去 0x10000，得到 0x0437。取该值的低 20 位，得到二进制值 0000 0000 0100 0011 0111。然后，取它高 10 位 —— 0000 0000 01，对应十六进制值为 0x0001，将它加上 0xD800 之后得到 0xD801，因此它的第一个 16 位编码单元的值就是 0xD801。最后，取 20 位值的低 10 位，得到 000011 0111，对应十六进制值为 0x0037，将它加上 0xDC00 得到 0xDC37，因此它的第二个 16 位编码单元的值就是 0xDC37。最后我们得到整个德撒律字母的 UTF-16 编码表示为：0xD801DC37。

> 第二个例子是古代汉字“碎”，它的码点定义为 0x24B62。第一步，我们先将该码点值减去 0x10000，得到 0x14B62。第二步取它的低 20 位，得到二进制值 0001 0100 10110110 0010。第三步，取前 10 位，得到 00 0101 0010，对应十六进制值为 0x0052，将它加上 0xD800 之后得到 0xD852，因此第一个 16 位编码单元的值就是 0xD852。第四步，取刚才所得 20 位值的低 10 位，得到 11 0110 0010，对应十六进制值为 0x0362，将它加上 0xDC00 得到 0xDF62，因此第二个 16 位编码单元的值就是 0xDF62。最终，该汉字的 UTF-16 编码表示为 0xD852 DF62。

3. 范围从 0xD800 到 0xDFFF 的区间

> Unicode 永久保留了这两个区间不允许定义任何有意义的字符码点。因为我们通过上面从 0x010000 到 0x10FFFF 范围的 UTF-16 编码表示法就已经知道这个区间用于 4 字节 UTF-16 编码的高位替换与低位替换区间，所以不能用来定义码点值，否则会在编码上产生歧义。

# 中文编码集

- GB2312<br>
    《信息交换用汉字编码字符集---基本集》<br>
    一共收录了 7445 个字符<br>
    包括 6763 个汉字和 682 个其它符号<bf>
    不支持国际 ISO 标准<br>
- GBK<br>
    《汉字内码扩展规范》<br>
    向下兼容 GB2312, 向上支持国际 ISO 标准<br>
    收录了 21003 个汉字, 支持全部中日韩汉字<br>

# 资源

[了不起的 Unicode！](https://mp.weixin.qq.com/s/GKpQkoujft2s6j95yZqzsA)<br>
